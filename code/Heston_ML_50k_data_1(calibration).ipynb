{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vewRJlHt2K_I",
        "outputId": "a1a6f8ad-7a1e-4293-dc15-0adf22979bfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-lego\n",
        "!pip install polars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PclXPYwC6sK5",
        "outputId": "9e6b8b41-b010-436e-a597-87fe9868158b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-lego\n",
            "  Downloading scikit_lego-0.6.14-py2.py3-none-any.whl (230 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m230.9/230.9 KB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Deprecated>=1.2.6\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: autograd>=1.2 in /usr/local/lib/python3.9/dist-packages (from scikit-lego) (1.5)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.9/dist-packages (from scikit-lego) (0.5.3)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.9/dist-packages (from scikit-lego) (1.4.4)\n",
            "Requirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.9/dist-packages (from scikit-lego) (1.2.2)\n",
            "Collecting umap-learn>=0.4.6\n",
            "  Downloading umap-learn-0.5.3.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.2/88.2 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.9/dist-packages (from autograd>=1.2->scikit-lego) (1.22.4)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.9/dist-packages (from autograd>=1.2->scikit-lego) (0.18.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.9/dist-packages (from Deprecated>=1.2.6->scikit-lego) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.5->scikit-lego) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.5->scikit-lego) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from patsy>=0.5.1->scikit-lego) (1.16.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.24.1->scikit-lego) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.24.1->scikit-lego) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.24.1->scikit-lego) (3.1.0)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.9/dist-packages (from umap-learn>=0.4.6->scikit-lego) (0.56.4)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.8.tar.gz (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from umap-learn>=0.4.6->scikit-lego) (4.65.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba>=0.49->umap-learn>=0.4.6->scikit-lego) (67.6.0)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba>=0.49->umap-learn>=0.4.6->scikit-lego) (0.39.1)\n",
            "Building wheels for collected packages: umap-learn, pynndescent\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.3-py3-none-any.whl size=82830 sha256=00a757e9118bea9600bd2e0619c1438fcf28cc3dfd50889d198f5cbeaa285d80\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/3e/1c/596d0a463d17475af648688443fa4846fef624d1390339e7e9\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.8-py3-none-any.whl size=55509 sha256=82c3b6f2a7a17a94208c1f1f5c954fc1554538b9ba400135aea68209448e0b0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/89/cc/59ab91ef5b21dc2ab3635528d7d227f49dfc9169905dcb959d\n",
            "Successfully built umap-learn pynndescent\n",
            "Installing collected packages: Deprecated, pynndescent, umap-learn, scikit-lego\n",
            "Successfully installed Deprecated-1.2.13 pynndescent-0.5.8 scikit-lego-0.6.14 umap-learn-0.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7F6v8UT3_hw"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "from scipy import stats\n",
        "from scipy.stats import norm\n",
        "\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/practicum_data/\")\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "from share_funcs import *\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGDOXf9_yjQA",
        "outputId": "1cfc8dc6-1e9b-48b2-fbea-db6a64c939ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujl9RZBm4NDa"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8zwxLS84Q6v"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ydIPXxc5DgL"
      },
      "source": [
        "# American Call Option - RF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-mloItVF3_jr",
        "outputId": "39fc88ea-df4f-4ffc-fdf6-b88b61c4c47d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          m         T         r         q        v0     theta     kappa  \\\n",
              "0  4.258717  1.680247  0.016304  0.041019  0.323511  1.807475  1.571375   \n",
              "1  2.274916  1.804915  0.058924  0.027882  0.496085  1.162404  0.670037   \n",
              "2  4.534160  0.670730  0.020643  0.030725  0.091455  1.815181  0.991059   \n",
              "3  4.753463  0.846062  0.026829  0.042381  0.145451  1.897037  0.809850   \n",
              "4  0.673201  0.114297  0.023764  0.021375  0.271200  0.301441  1.161399   \n",
              "\n",
              "      sigma       rho  eurocall_fourier  \n",
              "0  0.067568 -0.773899          0.191405  \n",
              "1  0.097001 -0.533752          0.226636  \n",
              "2  0.493723 -0.425484          0.001174  \n",
              "3  0.138594 -0.069301          0.007853  \n",
              "4  0.331472 -0.601016          0.327119  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb66448e-e37c-4fa6-83e5-5f48f5f35d9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>m</th>\n",
              "      <th>T</th>\n",
              "      <th>r</th>\n",
              "      <th>q</th>\n",
              "      <th>v0</th>\n",
              "      <th>theta</th>\n",
              "      <th>kappa</th>\n",
              "      <th>sigma</th>\n",
              "      <th>rho</th>\n",
              "      <th>eurocall_fourier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.258717</td>\n",
              "      <td>1.680247</td>\n",
              "      <td>0.016304</td>\n",
              "      <td>0.041019</td>\n",
              "      <td>0.323511</td>\n",
              "      <td>1.807475</td>\n",
              "      <td>1.571375</td>\n",
              "      <td>0.067568</td>\n",
              "      <td>-0.773899</td>\n",
              "      <td>0.191405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.274916</td>\n",
              "      <td>1.804915</td>\n",
              "      <td>0.058924</td>\n",
              "      <td>0.027882</td>\n",
              "      <td>0.496085</td>\n",
              "      <td>1.162404</td>\n",
              "      <td>0.670037</td>\n",
              "      <td>0.097001</td>\n",
              "      <td>-0.533752</td>\n",
              "      <td>0.226636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.534160</td>\n",
              "      <td>0.670730</td>\n",
              "      <td>0.020643</td>\n",
              "      <td>0.030725</td>\n",
              "      <td>0.091455</td>\n",
              "      <td>1.815181</td>\n",
              "      <td>0.991059</td>\n",
              "      <td>0.493723</td>\n",
              "      <td>-0.425484</td>\n",
              "      <td>0.001174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.753463</td>\n",
              "      <td>0.846062</td>\n",
              "      <td>0.026829</td>\n",
              "      <td>0.042381</td>\n",
              "      <td>0.145451</td>\n",
              "      <td>1.897037</td>\n",
              "      <td>0.809850</td>\n",
              "      <td>0.138594</td>\n",
              "      <td>-0.069301</td>\n",
              "      <td>0.007853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.673201</td>\n",
              "      <td>0.114297</td>\n",
              "      <td>0.023764</td>\n",
              "      <td>0.021375</td>\n",
              "      <td>0.271200</td>\n",
              "      <td>0.301441</td>\n",
              "      <td>1.161399</td>\n",
              "      <td>0.331472</td>\n",
              "      <td>-0.601016</td>\n",
              "      <td>0.327119</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb66448e-e37c-4fa6-83e5-5f48f5f35d9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb66448e-e37c-4fa6-83e5-5f48f5f35d9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb66448e-e37c-4fa6-83e5-5f48f5f35d9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Read data\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/practicum_data-American_Option/eurocall_fourier2.csv\", index_col=0)\n",
        "data.dropna(axis=0, how='any', inplace=True)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "((data['eurocall_fourier'] > 0) & (data['eurocall_fourier'] < 1e-5)).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wAherL4xhB6",
        "outputId": "acf59513-f3d9-410e-8c12-b8bc9e79c3e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False    50000\n",
              "Name: eurocall_fourier, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezNlxKYQ9u9P",
        "outputId": "996f8301-bc98-4a74-cef6-cc87a2128dbc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5135, 10)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Remove < 1e-5\n",
        "# data0 = copy.deepcopy(data)\n",
        "data['eurocall_fourier'] = data['eurocall_fourier'].apply(lambda x: 0 if x < 1e-5 else x)\n",
        "data[data['eurocall_fourier'] == 0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPWNtkyiDKPy",
        "outputId": "562bf04c-789d-4f5e-d3c1-7d4cbb3cd5c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5135, 10)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[data.eurocall_fourier == 0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsGlgVp53_mS"
      },
      "outputs": [],
      "source": [
        "# Data set\n",
        "rf_data = copy.deepcopy(data)\n",
        "\n",
        "# Split train/test data set\n",
        "X_rf = rf_data.drop(['eurocall_fourier'], axis=1)\n",
        "y_rf = rf_data['eurocall_fourier']\n",
        "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y_rf, test_size=0.3, random_state=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W85Prr17lmh"
      },
      "source": [
        "## Model Fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "KqB6UztH6UhW",
        "outputId": "64f7814f-9a6c-44de-b5b5-dd5e6367697d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Practicum/share_funcs.py\u001b[0m in \u001b[0;36mtrainmodel\u001b[0;34m(model, X_train, y_train, trained_params, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0mkflod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkflod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m   \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Model fit\n",
        "%%time\n",
        "trained_params_rf = {'n_estimators': [50, 100, 200, 400],\n",
        "                     'max_features': np.arange(1, 9)\n",
        "                     }\n",
        "grid_search_rf = trainmodel(RandomForestRegressor, X_train_rf, y_train_rf, trained_params_rf)\n",
        "rf_cv_results = pd.DataFrame(grid_search_rf.cv_results_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8qhv4mn6Ujc"
      },
      "outputs": [],
      "source": [
        "file_path_rf = '/content/drive/MyDrive/Practicum/rf_cv_results_1w.csv'\n",
        "#rf_cv_results.to_csv(file_path_rf)\n",
        "rf_cv_results = pd.read_csv(file_path_rf, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFydKyRn6UmC",
        "outputId": "ef762e65-6b34-44a6-f6f5-5b0fe209f296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Best RF Performance:\n",
            "RandomForestRegressor(max_features=5, n_estimators=500)\n",
            "Train Set rmse:  0.00561\n",
            "RF rmse:  0.01554 mae: 0.00957\n",
            "RF r2:  0.99348\n",
            "CPU times: user 1min 49s, sys: 873 ms, total: 1min 49s\n",
            "Wall time: 1min 50s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "rfr1 = train_best_reg(RandomForestRegressor, X_train_rf, y_train_rf, X_test_rf, y_test_rf,\n",
        "                      \"RF\", max_features=5, n_estimators=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-J83Gq0g6UoZ",
        "outputId": "bf9e2781-d1c6-4db7-b489-51c7546a0a1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Best RF Performance:\n",
            "RandomForestRegressor(max_features=5, n_estimators=400)\n",
            "Train Set rmse:  0.00565\n",
            "RF rmse:  0.01566 mae: 0.00961\n",
            "RF r2:  0.99338\n",
            "CPU times: user 1min 24s, sys: 946 ms, total: 1min 25s\n",
            "Wall time: 1min 25s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "rfr2 = train_best_reg(RandomForestRegressor, X_train_rf, y_train_rf, X_test_rf, y_test_rf,\n",
        "                      \"RF\", max_features=5, n_estimators=400)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_best(model, X_train: pd.DataFrame, y_train: Union[pd.DataFrame, pd.Series], X_test: pd.DataFrame,\n",
        "              y_test:Union[pd.DataFrame, pd.Series], name: str=\"Model\", **kwargs):\n",
        "  model_instance = model(**kwargs)\n",
        "  model_instance.fit(X_train, y_train)\n",
        "  print(f\"Current Best {name} Performance:\")\n",
        "  print(model_instance)\n",
        "  # y_test_predict = err_check(model_instance.predict(X_test))\n",
        "  y_test_predict = model_instance.predict(X_test)\n",
        "  rmse = np.around(np.sqrt(mean_squared_error(y_test, y_test_predict)), decimals=5)\n",
        "  mae = np.around(mean_absolute_error(y_test, y_test_predict), decimals=5)\n",
        "  r2 = np.around(r2_score(y_test, y_test_predict), decimals=5)\n",
        "  print(\"Train Set rmse: \", np.around(np.sqrt(mean_squared_error(y_train, model_instance.predict(X_train))), decimals=5))\n",
        "  print(f\"{name} rmse: \", rmse, \"mae:\", mae)\n",
        "  #print(f\"{name} r2: \", r2)\n",
        "  return model_instance,rmse\n",
        "\n",
        "score_lt = []\n",
        "nrange=[400,550,600]\n",
        "for i in range(25,30,1):\n",
        "  rfc = train_best(RandomForestRegressor, X_train_rf, y_train_rf, X_test_rf, y_test_rf,\n",
        "                      \"RF\", max_features=5, n_estimators=400,max_depth=i)\n",
        "  score = rfc[1]\n",
        "  score_lt.append(score)\n",
        "score_max = max(score_lt)\n",
        "\n",
        "print('最大得分：{}'.format(score_max),\n",
        "      '子树数量为：{}'.format(score_lt.index(score_max)*10+1))\n",
        "\n",
        "# 绘制学习曲线\n",
        "plt.subplot(111)\n",
        "plt.plot(score_lt, 'r-')\n",
        "plt.xlabel('n estimators')\n",
        "plt.ylabel('rsme')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EK83n5oDUfT7",
        "outputId": "bb686660-f915-4004-de24-5a77e9546e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Best RF Performance:\n",
            "RandomForestRegressor(max_depth=25, max_features=5, n_estimators=400)\n",
            "Train Set rmse:  0.00567\n",
            "RF rmse:  0.0156 mae: 0.00961\n",
            "Current Best RF Performance:\n",
            "RandomForestRegressor(max_depth=26, max_features=5, n_estimators=400)\n",
            "Train Set rmse:  0.0056\n",
            "RF rmse:  0.01561 mae: 0.00961\n",
            "Current Best RF Performance:\n",
            "RandomForestRegressor(max_depth=27, max_features=5, n_estimators=400)\n",
            "Train Set rmse:  0.00562\n",
            "RF rmse:  0.01567 mae: 0.00961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VAXeLaPX9KJR"
      },
      "source": [
        "## Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7y1YyY_K6Uyl",
        "outputId": "4186ddb4-571c-449a-baa1-52359da7e871"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RF Absolute Error (quantile): \n",
            "0.00    0.000\n",
            "0.25    0.001\n",
            "0.50    0.005\n",
            "0.75    0.014\n",
            "0.85    0.020\n",
            "0.90    0.025\n",
            "0.99    0.053\n",
            "1.00    0.526\n",
            "Name: eurocall_fourier, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Error\n",
        "# using model with n estimators = 400\n",
        "y_test_predict_rf = err_check(rfr2.predict(X_test_rf))\n",
        "err_rf = y_test_rf - y_test_predict_rf\n",
        "\n",
        "print('RF Absolute Error (quantile): ')\n",
        "print(np.around(err_rf.abs().quantile([0, 0.25, 0.5, 0.75, 0.85, 0.9, 0.99, 1]), decimals=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYtMpRO79qnx"
      },
      "source": [
        "## Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i5K2pv0r9lkb",
        "outputId": "62ca9bfc-7552-4643-d85d-7ecdbb71042c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family ['Calibri'] not found. Falling back to DejaVu Sans.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Model Feature Importance\n",
        "rf_feature_importance = pd.Series(rfr2.feature_importances_ / rfr2.feature_importances_.sum(),\n",
        "                                  index=['Moneyness(S/K)', 'Time to Maturity', 'Interest rate', 'Dividend','V0','theta','kappa','sigma','rho']).sort_values()\n",
        "plt.barh(rf_feature_importance.index, rf_feature_importance)\n",
        "plt.title(\"Random Forest: Feature Importance\\n$m \\in [0.2, 5,0]$\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3xAKwWTCcBt"
      },
      "source": [
        "# American Call Option - XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUugmXNTCbjz"
      },
      "outputs": [],
      "source": [
        "xgb_data = copy.deepcopy(data)\n",
        "\n",
        "# train/test data set for XGB\n",
        "X_xgb = xgb_data.drop(['eurocall_fourier'], axis=1)\n",
        "y_xgb = xgb_data['eurocall_fourier']\n",
        "X_train_xgb, X_test_xgb, y_train_xgb, y_test_xgb = train_test_split(X_xgb, y_xgb, test_size=0.3, random_state=10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_xgb_classify = (y_xgb > 0).astype(np.int64)\n",
        "\n",
        "y_train_xgb_classify = y_xgb_classify[y_train_xgb.index]\n",
        "y_test_xgb_classify = y_xgb_classify[y_test_xgb.index]\n"
      ],
      "metadata": {
        "id": "25fLvHtR7ecb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#98.52"
      ],
      "metadata": {
        "id": "AXwKPnjd83da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_xgb_clf1= train_best_clf(xgb.XGBClassifier, X_train_xgb, y_train_xgb_classify,X_test_xgb,y_test_xgb_classify,\"xgb classifier\", **{'eta':0.03,'colsample_bytree': 1, 'reg_alpha': 0,'reg_lambda': 1, 'max_depth':6, 'min_child_weight': 1, 'n_estimators': 800, 'subsample': 0.8})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaSog8bg7luf",
        "outputId": "bf17a27b-e498-4718-9770-665d122ed6ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Best xgb classifier Performance:\n",
            "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
            "              colsample_bylevel=None, colsample_bynode=None, colsample_bytree=1,\n",
            "              early_stopping_rounds=None, enable_categorical=False, eta=0.03,\n",
            "              eval_metric=None, feature_types=None, gamma=None, gpu_id=None,\n",
            "              grow_policy=None, importance_type=None,\n",
            "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
            "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
            "              max_delta_step=None, max_depth=6, max_leaves=None,\n",
            "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
            "              n_estimators=800, n_jobs=None, num_parallel_tree=None,\n",
            "              predictor=None, ...)\n",
            "Train Set rmse:  0.009258200997725514\n",
            "xgb classifier rmse:  0.11860297916438131 mae: 0.014066666666666667\n",
            "Accuracy 0.9859333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37q_zQsmDzWS"
      },
      "source": [
        "## Model Fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGN8VenLEx-P"
      },
      "outputs": [],
      "source": [
        "param_xgb = {'n_estimators': [200, 400, 800],\n",
        "             'subsample': [0.6, 0.8],\n",
        "             'colsample_bytree': [0.8, 1],\n",
        "             'lambda_l2': [0, 1],\n",
        "             'min_child_weight': [1, 5, 10],\n",
        "             'max_depth': [4, 5, 6]\n",
        "             }\n",
        "grid_xgb = trainmodel(xgb.XGBRegressor, X_train_xgb, y_train_xgb, param_xgb)\n",
        "xgb_cv_results = pd.DataFrame(grid_xgb.cv_results_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PU-jLPKlZGzw"
      },
      "outputs": [],
      "source": [
        "file_path_xgb = '/content/drive/MyDrive/Practicum/xgb_cv_results_1w.csv'\n",
        "#xgb_cv_results.to_csv(file_path_xgb)\n",
        "xgb_cv_results = pd.read_csv(file_path_xgb, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsTZPDXs91G8",
        "outputId": "6c43f7cb-62f2-4f60-d71c-d2ef2df12079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Best XGB Performance:\n",
            "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
            "             colsample_bylevel=None, colsample_bynode=None,\n",
            "             colsample_bytree=0.8, early_stopping_rounds=None,\n",
            "             enable_categorical=False, eta=0.05, eval_metric=None,\n",
            "             feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
            "             importance_type=None, interaction_constraints=None,\n",
            "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
            "             max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
            "             max_leaves=None, min_child_weight=1, missing=nan,\n",
            "             monotone_constraints=None, n_estimators=3200, n_jobs=None,\n",
            "             num_parallel_tree=None, predictor=None, ...)\n",
            "Train Set rmse:  0.00255\n",
            "XGB rmse:  0.0079 mae: 0.00537\n",
            "XGB r2:  0.99832\n"
          ]
        }
      ],
      "source": [
        "xgb1 = train_best_reg(xgb.XGBRegressor, X_train_xgb, y_train_xgb, X_test_xgb, y_test_xgb,\n",
        "                      'XGB', **{'eta':0.05,'colsample_bytree': 0.8, 'reg_alpha': 0,'reg_lambda': 0, 'min_child_weight': 1, 'n_estimators': 3200, 'subsample': 1, 'max_depth':6})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "**{'eta':0.04,'colsample_bytree': 0.8, 'reg_alpha': 0,'reg_lambda': 0, 'min_child_weight': 1, 'n_estimators': 3200, 'subsample': 1, 'max_depth':6}"
      ],
      "metadata": {
        "id": "Mwb37wuO03Rt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap2JfRRqDSNV",
        "outputId": "825808f5-91fc-4f3a-b58a-c0814b0d68a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Best XGB Performance:\n",
            "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
            "             colsample_bylevel=None, colsample_bynode=None,\n",
            "             colsample_bytree=0.8, early_stopping_rounds=None,\n",
            "             enable_categorical=False, eta=0.1, eval_metric=None,\n",
            "             feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
            "             importance_type=None, interaction_constraints=None,\n",
            "             learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
            "             max_cat_to_onehot=None, max_delta_step=None, max_depth=7,\n",
            "             max_leaves=None, min_child_weight=1, missing=nan,\n",
            "             monotone_constraints=None, n_estimators=800, n_jobs=None,\n",
            "             num_parallel_tree=None, objective='reg:absoluteerror', ...)\n",
            "Train Set rmse:  0.07814\n",
            "XGB rmse:  0.33198 mae: 0.23804\n",
            "XGB r2:  -1.9768\n"
          ]
        }
      ],
      "source": [
        "xgb2 = train_best_reg(xgb.XGBRegressor, X_train_xgb, y_train_xgb, X_test_xgb, y_test_xgb,\n",
        "                      'XGB', **{'eta':0.1,'colsample_bytree': 0.8, 'reg_alpha': 0,'reg_lambda': 0, 'min_child_weight': 1, 'n_estimators': 800, 'subsample': 0.8, 'max_depth':7,'objective':\"reg:absoluteerror\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxpExzJ1f2sj"
      },
      "source": [
        "## Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xLb6Y8AZDSQS",
        "outputId": "78fe36fe-ed07-4fc4-902c-90fcfdce9850"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGM Absolute Error (quantile): \n",
            "0.00    0.000\n",
            "0.25    0.043\n",
            "0.50    0.095\n",
            "0.75    0.177\n",
            "0.85    0.240\n",
            "0.90    0.288\n",
            "0.99    0.606\n",
            "1.00    2.057\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Error\n",
        "y_test_predict_xgb = pd.Series(xgb2.predict(X_test_xgb), index=y_test_xgb.index)\n",
        "err_xgb = y_test_xgb - y_test_predict_xgb\n",
        "\n",
        "print('XGM Absolute Error (quantile): ')\n",
        "print(np.around(err_xgb.abs().quantile([0, 0.25, 0.5, 0.75, 0.85, 0.9, 0.99, 1]), decimals=3))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_predict_xgb[y_test_xgb == 0].abs().sort_values(ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ikin_Xum5jOb",
        "outputId": "c51e10c8-6ddb-4caa-a2d2-54e6b58bc3f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14677    0.294958\n",
              "9870     0.100801\n",
              "18467    0.031527\n",
              "34128    0.030500\n",
              "34740    0.030207\n",
              "13348    0.024857\n",
              "61       0.023989\n",
              "10232    0.021721\n",
              "2518     0.021375\n",
              "39201    0.020086\n",
              "31740    0.019901\n",
              "22856    0.019762\n",
              "36324    0.019628\n",
              "35749    0.019460\n",
              "45210    0.018851\n",
              "21010    0.017913\n",
              "29642    0.017270\n",
              "39226    0.015994\n",
              "1275     0.015953\n",
              "47601    0.015356\n",
              "26613    0.015033\n",
              "24035    0.014926\n",
              "15533    0.014643\n",
              "21001    0.014228\n",
              "29120    0.014081\n",
              "10307    0.014078\n",
              "9923     0.013864\n",
              "6051     0.013857\n",
              "28810    0.013541\n",
              "4349     0.013338\n",
              "4088     0.013213\n",
              "26937    0.013098\n",
              "14981    0.013022\n",
              "3243     0.012591\n",
              "32642    0.012558\n",
              "14340    0.012452\n",
              "21100    0.012383\n",
              "43555    0.012301\n",
              "36806    0.012070\n",
              "24344    0.011955\n",
              "2794     0.011653\n",
              "29487    0.010982\n",
              "20046    0.010982\n",
              "45566    0.010826\n",
              "10740    0.010678\n",
              "31958    0.010542\n",
              "20661    0.010463\n",
              "49397    0.010447\n",
              "19535    0.010236\n",
              "17616    0.010103\n",
              "44693    0.010055\n",
              "42514    0.009845\n",
              "9888     0.009712\n",
              "11487    0.009709\n",
              "29497    0.009694\n",
              "4823     0.009600\n",
              "35449    0.009518\n",
              "11086    0.009508\n",
              "45102    0.009469\n",
              "38582    0.009461\n",
              "35327    0.009459\n",
              "41704    0.009450\n",
              "9685     0.009276\n",
              "45469    0.009207\n",
              "25262    0.009186\n",
              "22133    0.009186\n",
              "18637    0.009185\n",
              "13085    0.009177\n",
              "6202     0.009136\n",
              "43292    0.009132\n",
              "29033    0.009058\n",
              "15114    0.009032\n",
              "30709    0.008946\n",
              "47387    0.008911\n",
              "21320    0.008867\n",
              "35754    0.008838\n",
              "41054    0.008819\n",
              "24833    0.008811\n",
              "21217    0.008794\n",
              "48842    0.008749\n",
              "38927    0.008739\n",
              "48273    0.008721\n",
              "7603     0.008646\n",
              "44374    0.008559\n",
              "47585    0.008414\n",
              "17605    0.008395\n",
              "42107    0.008368\n",
              "31506    0.008360\n",
              "3708     0.008344\n",
              "3107     0.008337\n",
              "1331     0.008277\n",
              "38880    0.008267\n",
              "10066    0.008257\n",
              "16061    0.008222\n",
              "41093    0.008197\n",
              "40135    0.008188\n",
              "16935    0.008153\n",
              "20206    0.008112\n",
              "38455    0.007888\n",
              "27494    0.007862\n",
              "27297    0.007856\n",
              "36971    0.007838\n",
              "37997    0.007817\n",
              "12675    0.007792\n",
              "35490    0.007767\n",
              "1578     0.007743\n",
              "46933    0.007728\n",
              "33687    0.007674\n",
              "45532    0.007652\n",
              "20953    0.007581\n",
              "41020    0.007579\n",
              "36721    0.007462\n",
              "10813    0.007376\n",
              "12258    0.007364\n",
              "46526    0.007350\n",
              "11718    0.007333\n",
              "40760    0.007314\n",
              "48955    0.007296\n",
              "14545    0.007281\n",
              "12650    0.007278\n",
              "32191    0.007256\n",
              "47283    0.007207\n",
              "21339    0.007204\n",
              "27553    0.007178\n",
              "40349    0.007145\n",
              "9148     0.007120\n",
              "10093    0.007082\n",
              "28179    0.007074\n",
              "39743    0.007066\n",
              "7052     0.007049\n",
              "35415    0.006981\n",
              "12965    0.006919\n",
              "13567    0.006901\n",
              "40746    0.006828\n",
              "39646    0.006809\n",
              "20249    0.006795\n",
              "45634    0.006778\n",
              "15351    0.006764\n",
              "43001    0.006740\n",
              "38143    0.006739\n",
              "27817    0.006697\n",
              "34932    0.006694\n",
              "45650    0.006646\n",
              "11368    0.006568\n",
              "39249    0.006531\n",
              "47979    0.006454\n",
              "57       0.006418\n",
              "9154     0.006384\n",
              "10658    0.006376\n",
              "16588    0.006371\n",
              "29819    0.006349\n",
              "30869    0.006344\n",
              "38062    0.006341\n",
              "8230     0.006324\n",
              "30496    0.006287\n",
              "15499    0.006284\n",
              "28866    0.006265\n",
              "44287    0.006228\n",
              "238      0.006185\n",
              "5160     0.006172\n",
              "23812    0.006149\n",
              "715      0.006137\n",
              "17824    0.006129\n",
              "18865    0.006112\n",
              "27114    0.006106\n",
              "44607    0.006076\n",
              "38777    0.006042\n",
              "26843    0.006032\n",
              "16658    0.006023\n",
              "19251    0.006008\n",
              "17200    0.005986\n",
              "43019    0.005966\n",
              "24624    0.005948\n",
              "44027    0.005929\n",
              "14082    0.005918\n",
              "22998    0.005892\n",
              "9756     0.005891\n",
              "19361    0.005877\n",
              "20851    0.005867\n",
              "38370    0.005863\n",
              "8092     0.005857\n",
              "34754    0.005830\n",
              "8033     0.005802\n",
              "31374    0.005778\n",
              "3429     0.005778\n",
              "13280    0.005776\n",
              "7454     0.005764\n",
              "4249     0.005759\n",
              "10117    0.005752\n",
              "4641     0.005739\n",
              "22677    0.005735\n",
              "39402    0.005729\n",
              "27994    0.005702\n",
              "3254     0.005699\n",
              "31167    0.005685\n",
              "27639    0.005675\n",
              "48338    0.005648\n",
              "17933    0.005633\n",
              "41943    0.005623\n",
              "5973     0.005616\n",
              "37193    0.005614\n",
              "41200    0.005593\n",
              "23076    0.005590\n",
              "5225     0.005571\n",
              "25441    0.005561\n",
              "14060    0.005555\n",
              "18581    0.005534\n",
              "44121    0.005499\n",
              "14718    0.005476\n",
              "13319    0.005463\n",
              "259      0.005448\n",
              "26295    0.005433\n",
              "44227    0.005417\n",
              "3899     0.005356\n",
              "323      0.005348\n",
              "7227     0.005347\n",
              "19707    0.005337\n",
              "5724     0.005328\n",
              "8024     0.005325\n",
              "20256    0.005313\n",
              "47941    0.005300\n",
              "32790    0.005299\n",
              "34188    0.005295\n",
              "39247    0.005292\n",
              "16322    0.005267\n",
              "9467     0.005246\n",
              "37318    0.005211\n",
              "25782    0.005210\n",
              "19486    0.005202\n",
              "17659    0.005194\n",
              "26895    0.005190\n",
              "43728    0.005170\n",
              "6374     0.005134\n",
              "35842    0.005129\n",
              "42825    0.005128\n",
              "38759    0.005110\n",
              "48470    0.005058\n",
              "27550    0.005047\n",
              "43270    0.005031\n",
              "25473    0.005030\n",
              "33381    0.005000\n",
              "34396    0.004980\n",
              "29479    0.004972\n",
              "33690    0.004970\n",
              "10216    0.004964\n",
              "9485     0.004956\n",
              "37944    0.004933\n",
              "32798    0.004924\n",
              "37060    0.004919\n",
              "23498    0.004900\n",
              "38289    0.004899\n",
              "5313     0.004896\n",
              "34360    0.004852\n",
              "2436     0.004846\n",
              "12806    0.004841\n",
              "34253    0.004838\n",
              "24160    0.004822\n",
              "16853    0.004792\n",
              "15521    0.004783\n",
              "21685    0.004779\n",
              "22625    0.004778\n",
              "14669    0.004778\n",
              "14322    0.004772\n",
              "10530    0.004770\n",
              "25824    0.004759\n",
              "16062    0.004749\n",
              "34322    0.004733\n",
              "8854     0.004725\n",
              "41776    0.004705\n",
              "7417     0.004705\n",
              "3113     0.004697\n",
              "29466    0.004691\n",
              "5208     0.004685\n",
              "40827    0.004681\n",
              "32369    0.004677\n",
              "38160    0.004670\n",
              "25453    0.004657\n",
              "16360    0.004652\n",
              "42760    0.004649\n",
              "38506    0.004649\n",
              "15164    0.004639\n",
              "34393    0.004638\n",
              "34264    0.004599\n",
              "21350    0.004597\n",
              "15412    0.004587\n",
              "19394    0.004576\n",
              "47118    0.004563\n",
              "18149    0.004554\n",
              "48858    0.004553\n",
              "8701     0.004552\n",
              "15167    0.004542\n",
              "40147    0.004540\n",
              "7361     0.004537\n",
              "5862     0.004533\n",
              "37561    0.004523\n",
              "7937     0.004523\n",
              "6560     0.004516\n",
              "46645    0.004491\n",
              "24872    0.004483\n",
              "7406     0.004475\n",
              "44332    0.004464\n",
              "20343    0.004458\n",
              "42704    0.004452\n",
              "18741    0.004450\n",
              "27544    0.004431\n",
              "11636    0.004421\n",
              "43410    0.004417\n",
              "39428    0.004412\n",
              "12359    0.004390\n",
              "24118    0.004379\n",
              "42244    0.004378\n",
              "2709     0.004375\n",
              "8622     0.004359\n",
              "35278    0.004359\n",
              "10423    0.004357\n",
              "37809    0.004344\n",
              "37719    0.004338\n",
              "37085    0.004330\n",
              "41232    0.004289\n",
              "44237    0.004280\n",
              "18951    0.004278\n",
              "13658    0.004276\n",
              "4111     0.004271\n",
              "1763     0.004270\n",
              "5356     0.004267\n",
              "6177     0.004265\n",
              "1377     0.004206\n",
              "25251    0.004186\n",
              "46321    0.004172\n",
              "34510    0.004165\n",
              "33012    0.004164\n",
              "41717    0.004152\n",
              "7328     0.004150\n",
              "35073    0.004144\n",
              "24014    0.004131\n",
              "34136    0.004131\n",
              "18168    0.004120\n",
              "41873    0.004110\n",
              "39990    0.004107\n",
              "18892    0.004106\n",
              "16777    0.004105\n",
              "27671    0.004086\n",
              "13578    0.004086\n",
              "42396    0.004084\n",
              "22295    0.004081\n",
              "7681     0.004078\n",
              "11967    0.004078\n",
              "9498     0.004076\n",
              "13411    0.004051\n",
              "14571    0.004049\n",
              "25446    0.004048\n",
              "19039    0.004047\n",
              "20518    0.004043\n",
              "44352    0.004028\n",
              "8625     0.004026\n",
              "15142    0.004024\n",
              "43305    0.004007\n",
              "16941    0.004006\n",
              "39220    0.004005\n",
              "12540    0.003993\n",
              "39282    0.003987\n",
              "26034    0.003986\n",
              "17450    0.003975\n",
              "35682    0.003972\n",
              "39625    0.003964\n",
              "37724    0.003964\n",
              "39925    0.003945\n",
              "35338    0.003937\n",
              "36152    0.003927\n",
              "10608    0.003904\n",
              "20857    0.003902\n",
              "31040    0.003898\n",
              "35720    0.003892\n",
              "12488    0.003884\n",
              "25759    0.003883\n",
              "5624     0.003873\n",
              "970      0.003870\n",
              "18640    0.003864\n",
              "1103     0.003858\n",
              "31007    0.003854\n",
              "16099    0.003834\n",
              "26271    0.003825\n",
              "32810    0.003824\n",
              "27055    0.003824\n",
              "38575    0.003823\n",
              "11093    0.003820\n",
              "1693     0.003801\n",
              "29886    0.003792\n",
              "18931    0.003791\n",
              "40399    0.003785\n",
              "21086    0.003782\n",
              "14163    0.003782\n",
              "2701     0.003776\n",
              "33238    0.003775\n",
              "384      0.003760\n",
              "19877    0.003744\n",
              "2744     0.003721\n",
              "14483    0.003701\n",
              "43807    0.003691\n",
              "31064    0.003690\n",
              "32961    0.003687\n",
              "2429     0.003673\n",
              "29709    0.003671\n",
              "20720    0.003668\n",
              "16500    0.003664\n",
              "42068    0.003657\n",
              "36264    0.003657\n",
              "9303     0.003648\n",
              "47494    0.003641\n",
              "21294    0.003619\n",
              "34847    0.003618\n",
              "6509     0.003618\n",
              "16656    0.003612\n",
              "32603    0.003611\n",
              "33674    0.003603\n",
              "42392    0.003599\n",
              "8276     0.003593\n",
              "47311    0.003593\n",
              "44711    0.003587\n",
              "3831     0.003586\n",
              "26553    0.003565\n",
              "45782    0.003559\n",
              "38304    0.003553\n",
              "47230    0.003553\n",
              "16103    0.003546\n",
              "29282    0.003545\n",
              "22518    0.003545\n",
              "42992    0.003518\n",
              "28143    0.003512\n",
              "48361    0.003511\n",
              "11910    0.003509\n",
              "35061    0.003505\n",
              "44957    0.003491\n",
              "2234     0.003490\n",
              "32752    0.003489\n",
              "14159    0.003481\n",
              "10084    0.003479\n",
              "14377    0.003471\n",
              "4033     0.003470\n",
              "17128    0.003468\n",
              "41278    0.003467\n",
              "29102    0.003447\n",
              "11529    0.003426\n",
              "36427    0.003412\n",
              "2443     0.003409\n",
              "23653    0.003398\n",
              "2408     0.003394\n",
              "12951    0.003393\n",
              "36603    0.003379\n",
              "616      0.003376\n",
              "44294    0.003375\n",
              "19791    0.003375\n",
              "42640    0.003374\n",
              "4881     0.003373\n",
              "39985    0.003372\n",
              "19604    0.003371\n",
              "28550    0.003366\n",
              "13751    0.003366\n",
              "44680    0.003354\n",
              "9521     0.003333\n",
              "6605     0.003320\n",
              "44773    0.003320\n",
              "45149    0.003310\n",
              "49929    0.003309\n",
              "30670    0.003308\n",
              "11121    0.003298\n",
              "15985    0.003297\n",
              "1242     0.003291\n",
              "36312    0.003289\n",
              "19872    0.003288\n",
              "28828    0.003288\n",
              "13943    0.003263\n",
              "2920     0.003256\n",
              "18695    0.003256\n",
              "7295     0.003253\n",
              "24829    0.003252\n",
              "12266    0.003238\n",
              "19049    0.003234\n",
              "6589     0.003233\n",
              "40308    0.003227\n",
              "32705    0.003226\n",
              "15446    0.003218\n",
              "30416    0.003213\n",
              "49227    0.003209\n",
              "49106    0.003191\n",
              "36374    0.003190\n",
              "22972    0.003178\n",
              "39967    0.003172\n",
              "5963     0.003172\n",
              "7076     0.003170\n",
              "42093    0.003163\n",
              "4965     0.003154\n",
              "26300    0.003144\n",
              "4104     0.003143\n",
              "33558    0.003131\n",
              "38758    0.003123\n",
              "34067    0.003121\n",
              "33636    0.003120\n",
              "1302     0.003105\n",
              "43781    0.003101\n",
              "19337    0.003101\n",
              "46347    0.003098\n",
              "11269    0.003087\n",
              "33394    0.003074\n",
              "40768    0.003050\n",
              "30223    0.003040\n",
              "14490    0.003030\n",
              "1142     0.003025\n",
              "32054    0.003022\n",
              "31967    0.003021\n",
              "21668    0.003017\n",
              "9515     0.003015\n",
              "14181    0.003011\n",
              "25664    0.003000\n",
              "19403    0.002990\n",
              "28513    0.002987\n",
              "30123    0.002978\n",
              "9015     0.002971\n",
              "45802    0.002964\n",
              "33912    0.002944\n",
              "29243    0.002942\n",
              "12055    0.002937\n",
              "22623    0.002933\n",
              "3422     0.002923\n",
              "9525     0.002919\n",
              "2739     0.002918\n",
              "30011    0.002917\n",
              "37689    0.002916\n",
              "35487    0.002910\n",
              "257      0.002905\n",
              "40038    0.002904\n",
              "39179    0.002898\n",
              "46505    0.002892\n",
              "9996     0.002887\n",
              "33068    0.002885\n",
              "20160    0.002885\n",
              "9911     0.002883\n",
              "49271    0.002881\n",
              "30168    0.002880\n",
              "43183    0.002875\n",
              "13463    0.002871\n",
              "15271    0.002868\n",
              "23896    0.002868\n",
              "10210    0.002867\n",
              "15606    0.002867\n",
              "19529    0.002865\n",
              "8754     0.002860\n",
              "31551    0.002856\n",
              "39489    0.002856\n",
              "42060    0.002843\n",
              "46495    0.002841\n",
              "16507    0.002839\n",
              "5262     0.002837\n",
              "21191    0.002835\n",
              "40618    0.002821\n",
              "3913     0.002819\n",
              "27282    0.002812\n",
              "499      0.002809\n",
              "33041    0.002804\n",
              "28449    0.002799\n",
              "32802    0.002796\n",
              "10421    0.002795\n",
              "43286    0.002784\n",
              "29284    0.002778\n",
              "19586    0.002774\n",
              "14846    0.002771\n",
              "19652    0.002771\n",
              "12840    0.002768\n",
              "42004    0.002766\n",
              "20170    0.002761\n",
              "4768     0.002758\n",
              "25611    0.002755\n",
              "30539    0.002754\n",
              "10964    0.002746\n",
              "39110    0.002744\n",
              "26649    0.002739\n",
              "11597    0.002723\n",
              "6032     0.002721\n",
              "18798    0.002689\n",
              "15611    0.002683\n",
              "38451    0.002668\n",
              "41211    0.002667\n",
              "8721     0.002665\n",
              "5087     0.002662\n",
              "38613    0.002656\n",
              "7144     0.002656\n",
              "2220     0.002654\n",
              "43692    0.002639\n",
              "11820    0.002633\n",
              "25097    0.002630\n",
              "20270    0.002629\n",
              "36588    0.002624\n",
              "47017    0.002624\n",
              "30166    0.002623\n",
              "15683    0.002619\n",
              "47890    0.002619\n",
              "16437    0.002619\n",
              "937      0.002618\n",
              "41260    0.002609\n",
              "44382    0.002602\n",
              "40032    0.002601\n",
              "42939    0.002598\n",
              "28431    0.002589\n",
              "9405     0.002587\n",
              "21003    0.002579\n",
              "46825    0.002578\n",
              "4786     0.002574\n",
              "22094    0.002571\n",
              "6928     0.002571\n",
              "35292    0.002567\n",
              "10442    0.002555\n",
              "35911    0.002552\n",
              "12728    0.002550\n",
              "9180     0.002541\n",
              "47988    0.002534\n",
              "38868    0.002530\n",
              "33007    0.002528\n",
              "543      0.002524\n",
              "2838     0.002521\n",
              "62       0.002521\n",
              "17617    0.002520\n",
              "39305    0.002519\n",
              "39144    0.002518\n",
              "30250    0.002511\n",
              "49588    0.002504\n",
              "12904    0.002500\n",
              "14843    0.002496\n",
              "11588    0.002494\n",
              "4084     0.002489\n",
              "32400    0.002487\n",
              "2972     0.002477\n",
              "48528    0.002475\n",
              "8308     0.002474\n",
              "45245    0.002469\n",
              "39920    0.002464\n",
              "33634    0.002460\n",
              "13272    0.002452\n",
              "49308    0.002437\n",
              "10097    0.002429\n",
              "44238    0.002420\n",
              "11220    0.002416\n",
              "29837    0.002410\n",
              "38682    0.002407\n",
              "15219    0.002405\n",
              "33186    0.002403\n",
              "49707    0.002401\n",
              "3881     0.002396\n",
              "10339    0.002392\n",
              "10065    0.002392\n",
              "43363    0.002390\n",
              "14984    0.002389\n",
              "43378    0.002383\n",
              "17443    0.002378\n",
              "46180    0.002373\n",
              "29967    0.002371\n",
              "24353    0.002370\n",
              "26812    0.002370\n",
              "1780     0.002364\n",
              "7499     0.002354\n",
              "28646    0.002354\n",
              "30852    0.002343\n",
              "9687     0.002341\n",
              "40596    0.002340\n",
              "16763    0.002339\n",
              "43904    0.002337\n",
              "46267    0.002333\n",
              "37913    0.002326\n",
              "22403    0.002324\n",
              "28723    0.002318\n",
              "1837     0.002312\n",
              "24335    0.002304\n",
              "20061    0.002299\n",
              "16132    0.002296\n",
              "24464    0.002296\n",
              "40703    0.002295\n",
              "33467    0.002293\n",
              "30885    0.002292\n",
              "40314    0.002291\n",
              "10768    0.002289\n",
              "2869     0.002289\n",
              "14710    0.002286\n",
              "42839    0.002274\n",
              "27275    0.002266\n",
              "43716    0.002266\n",
              "11991    0.002263\n",
              "49246    0.002261\n",
              "266      0.002260\n",
              "3143     0.002257\n",
              "39456    0.002256\n",
              "49921    0.002255\n",
              "34305    0.002250\n",
              "22042    0.002240\n",
              "41874    0.002238\n",
              "486      0.002230\n",
              "40939    0.002228\n",
              "32616    0.002221\n",
              "29383    0.002216\n",
              "14830    0.002216\n",
              "41078    0.002215\n",
              "35360    0.002214\n",
              "25165    0.002212\n",
              "10481    0.002210\n",
              "13392    0.002209\n",
              "46687    0.002202\n",
              "35146    0.002200\n",
              "3359     0.002195\n",
              "33252    0.002191\n",
              "28093    0.002190\n",
              "42521    0.002185\n",
              "12464    0.002183\n",
              "46425    0.002173\n",
              "3761     0.002170\n",
              "3731     0.002167\n",
              "34559    0.002166\n",
              "37602    0.002162\n",
              "43121    0.002153\n",
              "10735    0.002147\n",
              "7323     0.002143\n",
              "33292    0.002143\n",
              "46286    0.002130\n",
              "14728    0.002126\n",
              "12005    0.002124\n",
              "15072    0.002123\n",
              "36999    0.002118\n",
              "8298     0.002113\n",
              "36530    0.002108\n",
              "13585    0.002096\n",
              "5693     0.002093\n",
              "40146    0.002089\n",
              "3172     0.002086\n",
              "17499    0.002084\n",
              "32881    0.002081\n",
              "19299    0.002080\n",
              "34119    0.002078\n",
              "18958    0.002076\n",
              "26961    0.002071\n",
              "30291    0.002068\n",
              "29000    0.002064\n",
              "18028    0.002064\n",
              "23121    0.002058\n",
              "20768    0.002054\n",
              "40972    0.002050\n",
              "23474    0.002046\n",
              "15821    0.002033\n",
              "46297    0.002028\n",
              "792      0.002027\n",
              "13327    0.002024\n",
              "42366    0.002023\n",
              "23727    0.002009\n",
              "36814    0.002004\n",
              "19417    0.002001\n",
              "40860    0.002000\n",
              "47190    0.001998\n",
              "4984     0.001987\n",
              "10157    0.001984\n",
              "18670    0.001984\n",
              "10552    0.001983\n",
              "10528    0.001980\n",
              "17853    0.001974\n",
              "39048    0.001973\n",
              "14452    0.001969\n",
              "31465    0.001964\n",
              "32858    0.001953\n",
              "11673    0.001948\n",
              "40843    0.001945\n",
              "27457    0.001935\n",
              "6464     0.001929\n",
              "39397    0.001928\n",
              "42204    0.001925\n",
              "11205    0.001922\n",
              "42291    0.001922\n",
              "1124     0.001913\n",
              "26793    0.001906\n",
              "23357    0.001905\n",
              "30203    0.001901\n",
              "10129    0.001898\n",
              "35417    0.001898\n",
              "3153     0.001895\n",
              "36392    0.001892\n",
              "43846    0.001891\n",
              "27650    0.001890\n",
              "9912     0.001889\n",
              "49904    0.001889\n",
              "23327    0.001886\n",
              "45523    0.001886\n",
              "9501     0.001883\n",
              "41033    0.001880\n",
              "48969    0.001875\n",
              "34696    0.001870\n",
              "30898    0.001858\n",
              "42627    0.001858\n",
              "1778     0.001858\n",
              "18516    0.001855\n",
              "46585    0.001845\n",
              "27149    0.001842\n",
              "18568    0.001841\n",
              "3556     0.001838\n",
              "14302    0.001834\n",
              "19752    0.001825\n",
              "5173     0.001824\n",
              "36350    0.001821\n",
              "28340    0.001815\n",
              "28246    0.001811\n",
              "22348    0.001810\n",
              "4341     0.001810\n",
              "2665     0.001808\n",
              "16659    0.001806\n",
              "16531    0.001804\n",
              "13455    0.001799\n",
              "34172    0.001796\n",
              "35577    0.001794\n",
              "36018    0.001793\n",
              "27369    0.001785\n",
              "41950    0.001785\n",
              "29692    0.001784\n",
              "47110    0.001778\n",
              "30757    0.001777\n",
              "40534    0.001775\n",
              "4391     0.001765\n",
              "12406    0.001757\n",
              "38753    0.001751\n",
              "9        0.001746\n",
              "4123     0.001745\n",
              "36474    0.001741\n",
              "20351    0.001741\n",
              "34441    0.001739\n",
              "34226    0.001735\n",
              "33277    0.001731\n",
              "15964    0.001724\n",
              "23350    0.001722\n",
              "3597     0.001721\n",
              "23109    0.001719\n",
              "43568    0.001713\n",
              "17502    0.001712\n",
              "3505     0.001711\n",
              "1991     0.001710\n",
              "3672     0.001705\n",
              "14847    0.001704\n",
              "42726    0.001697\n",
              "113      0.001697\n",
              "27232    0.001694\n",
              "9382     0.001690\n",
              "34825    0.001684\n",
              "12521    0.001683\n",
              "8925     0.001683\n",
              "45716    0.001681\n",
              "15208    0.001678\n",
              "24348    0.001674\n",
              "40980    0.001666\n",
              "28160    0.001665\n",
              "46651    0.001664\n",
              "37787    0.001662\n",
              "28210    0.001661\n",
              "5216     0.001659\n",
              "4535     0.001655\n",
              "18250    0.001651\n",
              "39590    0.001647\n",
              "49524    0.001646\n",
              "42482    0.001644\n",
              "6921     0.001642\n",
              "34013    0.001640\n",
              "10025    0.001634\n",
              "18979    0.001632\n",
              "4469     0.001622\n",
              "33541    0.001614\n",
              "1747     0.001613\n",
              "23605    0.001613\n",
              "40390    0.001612\n",
              "11950    0.001608\n",
              "28740    0.001604\n",
              "47668    0.001603\n",
              "42882    0.001600\n",
              "7138     0.001597\n",
              "2831     0.001594\n",
              "14454    0.001584\n",
              "48685    0.001583\n",
              "36943    0.001582\n",
              "28365    0.001576\n",
              "10910    0.001575\n",
              "15010    0.001575\n",
              "23298    0.001572\n",
              "2204     0.001570\n",
              "37572    0.001566\n",
              "22695    0.001565\n",
              "4791     0.001561\n",
              "17930    0.001559\n",
              "32088    0.001556\n",
              "8348     0.001544\n",
              "18694    0.001544\n",
              "13245    0.001541\n",
              "43253    0.001531\n",
              "44494    0.001528\n",
              "20927    0.001528\n",
              "19580    0.001526\n",
              "42999    0.001524\n",
              "47543    0.001522\n",
              "33749    0.001519\n",
              "40284    0.001512\n",
              "4113     0.001507\n",
              "15297    0.001499\n",
              "27992    0.001498\n",
              "767      0.001495\n",
              "7236     0.001494\n",
              "18978    0.001494\n",
              "10871    0.001494\n",
              "12624    0.001494\n",
              "37317    0.001491\n",
              "46378    0.001490\n",
              "16993    0.001481\n",
              "14395    0.001479\n",
              "28965    0.001478\n",
              "40541    0.001477\n",
              "20020    0.001477\n",
              "36144    0.001474\n",
              "20825    0.001474\n",
              "46727    0.001467\n",
              "537      0.001465\n",
              "8874     0.001464\n",
              "7847     0.001463\n",
              "25268    0.001461\n",
              "12288    0.001460\n",
              "29124    0.001459\n",
              "44955    0.001458\n",
              "20528    0.001455\n",
              "14975    0.001453\n",
              "8275     0.001452\n",
              "2448     0.001445\n",
              "17907    0.001440\n",
              "45884    0.001439\n",
              "613      0.001438\n",
              "44665    0.001437\n",
              "10096    0.001437\n",
              "46293    0.001434\n",
              "40198    0.001424\n",
              "5221     0.001423\n",
              "32357    0.001418\n",
              "10396    0.001418\n",
              "35852    0.001415\n",
              "7436     0.001415\n",
              "27475    0.001411\n",
              "48716    0.001411\n",
              "7101     0.001410\n",
              "6257     0.001402\n",
              "41150    0.001401\n",
              "10398    0.001400\n",
              "34858    0.001400\n",
              "7400     0.001398\n",
              "1592     0.001395\n",
              "46308    0.001393\n",
              "47179    0.001389\n",
              "4685     0.001387\n",
              "10259    0.001383\n",
              "38449    0.001381\n",
              "3990     0.001379\n",
              "23639    0.001379\n",
              "5690     0.001378\n",
              "16315    0.001377\n",
              "33567    0.001376\n",
              "7307     0.001372\n",
              "27566    0.001370\n",
              "45208    0.001368\n",
              "29457    0.001368\n",
              "48477    0.001367\n",
              "48297    0.001360\n",
              "3634     0.001358\n",
              "21686    0.001354\n",
              "28924    0.001353\n",
              "40916    0.001352\n",
              "28919    0.001344\n",
              "41262    0.001344\n",
              "45754    0.001344\n",
              "25893    0.001344\n",
              "4438     0.001338\n",
              "30735    0.001335\n",
              "29618    0.001335\n",
              "46392    0.001333\n",
              "34900    0.001328\n",
              "28916    0.001323\n",
              "4256     0.001320\n",
              "40228    0.001315\n",
              "40248    0.001315\n",
              "44572    0.001309\n",
              "31751    0.001309\n",
              "5927     0.001302\n",
              "42747    0.001296\n",
              "25327    0.001296\n",
              "42492    0.001292\n",
              "14079    0.001292\n",
              "40161    0.001290\n",
              "22530    0.001280\n",
              "14834    0.001275\n",
              "22015    0.001271\n",
              "36634    0.001267\n",
              "3010     0.001264\n",
              "32190    0.001263\n",
              "42699    0.001262\n",
              "15976    0.001259\n",
              "36798    0.001254\n",
              "3384     0.001253\n",
              "3485     0.001252\n",
              "20233    0.001250\n",
              "10091    0.001245\n",
              "46458    0.001243\n",
              "49567    0.001242\n",
              "24997    0.001238\n",
              "42583    0.001238\n",
              "1271     0.001236\n",
              "46547    0.001233\n",
              "16096    0.001230\n",
              "18372    0.001227\n",
              "13713    0.001226\n",
              "4096     0.001222\n",
              "40682    0.001221\n",
              "27876    0.001220\n",
              "7012     0.001213\n",
              "35170    0.001212\n",
              "22884    0.001212\n",
              "10333    0.001212\n",
              "48547    0.001210\n",
              "32072    0.001207\n",
              "34158    0.001206\n",
              "26023    0.001205\n",
              "12203    0.001201\n",
              "37292    0.001201\n",
              "5688     0.001200\n",
              "31774    0.001196\n",
              "41246    0.001193\n",
              "32172    0.001192\n",
              "33892    0.001192\n",
              "24671    0.001188\n",
              "27600    0.001185\n",
              "16166    0.001184\n",
              "25012    0.001184\n",
              "20792    0.001183\n",
              "17728    0.001181\n",
              "49932    0.001180\n",
              "15317    0.001178\n",
              "5818     0.001176\n",
              "20568    0.001174\n",
              "22762    0.001165\n",
              "2286     0.001164\n",
              "41500    0.001163\n",
              "28198    0.001162\n",
              "20293    0.001161\n",
              "32193    0.001160\n",
              "19938    0.001156\n",
              "42851    0.001154\n",
              "10824    0.001154\n",
              "24254    0.001152\n",
              "48993    0.001151\n",
              "41109    0.001145\n",
              "49817    0.001145\n",
              "23046    0.001141\n",
              "13205    0.001141\n",
              "23209    0.001140\n",
              "35103    0.001137\n",
              "39245    0.001137\n",
              "43562    0.001136\n",
              "26145    0.001129\n",
              "10064    0.001126\n",
              "17253    0.001123\n",
              "1607     0.001122\n",
              "10651    0.001122\n",
              "7949     0.001120\n",
              "42446    0.001118\n",
              "18057    0.001117\n",
              "1931     0.001112\n",
              "37347    0.001111\n",
              "1701     0.001111\n",
              "4091     0.001109\n",
              "18522    0.001107\n",
              "36306    0.001106\n",
              "36831    0.001101\n",
              "39868    0.001099\n",
              "20853    0.001091\n",
              "5282     0.001091\n",
              "4577     0.001091\n",
              "26523    0.001090\n",
              "30508    0.001088\n",
              "25917    0.001087\n",
              "40036    0.001085\n",
              "30628    0.001084\n",
              "11179    0.001077\n",
              "3896     0.001077\n",
              "41329    0.001076\n",
              "42667    0.001075\n",
              "42680    0.001072\n",
              "13240    0.001071\n",
              "27855    0.001069\n",
              "1153     0.001064\n",
              "15895    0.001062\n",
              "993      0.001054\n",
              "29373    0.001053\n",
              "29004    0.001053\n",
              "32210    0.001047\n",
              "28996    0.001043\n",
              "33740    0.001042\n",
              "12324    0.001039\n",
              "47569    0.001032\n",
              "4141     0.001026\n",
              "36129    0.001024\n",
              "1033     0.001015\n",
              "32262    0.001015\n",
              "35905    0.001013\n",
              "5446     0.001012\n",
              "641      0.001011\n",
              "7003     0.001009\n",
              "16917    0.001008\n",
              "35111    0.001007\n",
              "25295    0.001006\n",
              "19966    0.000988\n",
              "4147     0.000988\n",
              "19297    0.000988\n",
              "48414    0.000985\n",
              "3755     0.000983\n",
              "30116    0.000981\n",
              "42078    0.000979\n",
              "21004    0.000979\n",
              "49909    0.000976\n",
              "20311    0.000975\n",
              "10508    0.000972\n",
              "40850    0.000968\n",
              "3839     0.000967\n",
              "38765    0.000964\n",
              "31651    0.000964\n",
              "33340    0.000963\n",
              "38377    0.000961\n",
              "27337    0.000955\n",
              "46644    0.000955\n",
              "18634    0.000948\n",
              "27540    0.000948\n",
              "25501    0.000947\n",
              "32598    0.000940\n",
              "7766     0.000939\n",
              "46259    0.000931\n",
              "44864    0.000927\n",
              "5384     0.000925\n",
              "45489    0.000924\n",
              "11606    0.000921\n",
              "5189     0.000920\n",
              "44304    0.000912\n",
              "25494    0.000900\n",
              "47916    0.000898\n",
              "31695    0.000892\n",
              "25564    0.000890\n",
              "26343    0.000889\n",
              "35662    0.000886\n",
              "5217     0.000885\n",
              "25300    0.000884\n",
              "26189    0.000884\n",
              "37885    0.000883\n",
              "33660    0.000883\n",
              "43880    0.000880\n",
              "27415    0.000879\n",
              "41477    0.000874\n",
              "17642    0.000873\n",
              "3714     0.000869\n",
              "45158    0.000868\n",
              "37546    0.000866\n",
              "31847    0.000865\n",
              "29520    0.000865\n",
              "18834    0.000865\n",
              "12165    0.000862\n",
              "17917    0.000860\n",
              "39966    0.000859\n",
              "32297    0.000857\n",
              "5921     0.000854\n",
              "42415    0.000851\n",
              "28613    0.000847\n",
              "42526    0.000841\n",
              "18376    0.000839\n",
              "14081    0.000839\n",
              "35725    0.000836\n",
              "10349    0.000836\n",
              "37110    0.000832\n",
              "8065     0.000832\n",
              "36175    0.000831\n",
              "36892    0.000831\n",
              "32406    0.000826\n",
              "13504    0.000822\n",
              "78       0.000819\n",
              "42626    0.000818\n",
              "10294    0.000817\n",
              "19674    0.000817\n",
              "26639    0.000817\n",
              "20009    0.000814\n",
              "33978    0.000811\n",
              "32944    0.000809\n",
              "7760     0.000808\n",
              "25266    0.000805\n",
              "48892    0.000803\n",
              "41280    0.000802\n",
              "40004    0.000801\n",
              "24738    0.000800\n",
              "35162    0.000800\n",
              "32504    0.000799\n",
              "2949     0.000796\n",
              "33593    0.000796\n",
              "45577    0.000791\n",
              "16815    0.000786\n",
              "36436    0.000786\n",
              "5654     0.000784\n",
              "49474    0.000784\n",
              "28652    0.000783\n",
              "32932    0.000777\n",
              "33598    0.000777\n",
              "17420    0.000777\n",
              "44170    0.000776\n",
              "4200     0.000771\n",
              "36448    0.000770\n",
              "33902    0.000769\n",
              "19385    0.000768\n",
              "47278    0.000766\n",
              "26031    0.000762\n",
              "38989    0.000758\n",
              "32464    0.000757\n",
              "31636    0.000755\n",
              "39329    0.000744\n",
              "38103    0.000744\n",
              "48882    0.000744\n",
              "45842    0.000742\n",
              "32837    0.000739\n",
              "26671    0.000739\n",
              "45419    0.000738\n",
              "48248    0.000737\n",
              "42936    0.000736\n",
              "49410    0.000730\n",
              "16438    0.000727\n",
              "7346     0.000722\n",
              "49361    0.000717\n",
              "10363    0.000715\n",
              "24291    0.000711\n",
              "11854    0.000707\n",
              "33828    0.000707\n",
              "48069    0.000706\n",
              "30377    0.000706\n",
              "38955    0.000701\n",
              "629      0.000691\n",
              "21449    0.000691\n",
              "29483    0.000690\n",
              "34612    0.000689\n",
              "14827    0.000686\n",
              "26634    0.000684\n",
              "43769    0.000683\n",
              "27571    0.000683\n",
              "39905    0.000683\n",
              "28525    0.000682\n",
              "32167    0.000681\n",
              "44083    0.000680\n",
              "6529     0.000677\n",
              "30235    0.000673\n",
              "24300    0.000672\n",
              "30451    0.000669\n",
              "9763     0.000669\n",
              "42       0.000665\n",
              "18790    0.000664\n",
              "11534    0.000658\n",
              "45127    0.000651\n",
              "9963     0.000650\n",
              "18788    0.000649\n",
              "32213    0.000649\n",
              "39875    0.000647\n",
              "11765    0.000640\n",
              "37161    0.000640\n",
              "35268    0.000634\n",
              "47135    0.000633\n",
              "39586    0.000631\n",
              "13248    0.000630\n",
              "10082    0.000623\n",
              "49419    0.000619\n",
              "4885     0.000606\n",
              "7696     0.000606\n",
              "49573    0.000605\n",
              "9406     0.000598\n",
              "39406    0.000598\n",
              "42806    0.000595\n",
              "44706    0.000590\n",
              "4418     0.000587\n",
              "26905    0.000585\n",
              "8369     0.000584\n",
              "49465    0.000573\n",
              "22143    0.000573\n",
              "18681    0.000572\n",
              "37416    0.000565\n",
              "40545    0.000562\n",
              "9697     0.000550\n",
              "7047     0.000550\n",
              "30045    0.000546\n",
              "25082    0.000541\n",
              "47908    0.000539\n",
              "11560    0.000536\n",
              "20849    0.000536\n",
              "15529    0.000536\n",
              "24484    0.000534\n",
              "29228    0.000534\n",
              "17024    0.000530\n",
              "40758    0.000530\n",
              "40213    0.000528\n",
              "42023    0.000528\n",
              "2813     0.000524\n",
              "39554    0.000522\n",
              "35431    0.000521\n",
              "29193    0.000518\n",
              "28493    0.000515\n",
              "16249    0.000515\n",
              "31288    0.000508\n",
              "39126    0.000503\n",
              "11170    0.000500\n",
              "21691    0.000497\n",
              "8727     0.000490\n",
              "46696    0.000482\n",
              "27557    0.000481\n",
              "11202    0.000478\n",
              "27121    0.000471\n",
              "18299    0.000459\n",
              "30215    0.000458\n",
              "42301    0.000453\n",
              "19693    0.000451\n",
              "9024     0.000448\n",
              "30758    0.000447\n",
              "44434    0.000447\n",
              "12001    0.000444\n",
              "43998    0.000439\n",
              "30074    0.000439\n",
              "31328    0.000439\n",
              "8609     0.000437\n",
              "10763    0.000432\n",
              "33534    0.000429\n",
              "29813    0.000425\n",
              "9067     0.000420\n",
              "49544    0.000418\n",
              "11874    0.000413\n",
              "33666    0.000405\n",
              "22113    0.000404\n",
              "3607     0.000404\n",
              "12139    0.000402\n",
              "39729    0.000397\n",
              "34480    0.000396\n",
              "4513     0.000395\n",
              "44016    0.000395\n",
              "36443    0.000390\n",
              "49142    0.000388\n",
              "42641    0.000386\n",
              "41213    0.000383\n",
              "7688     0.000382\n",
              "992      0.000380\n",
              "44861    0.000370\n",
              "6191     0.000368\n",
              "23958    0.000367\n",
              "47853    0.000367\n",
              "45021    0.000366\n",
              "5760     0.000365\n",
              "30248    0.000363\n",
              "49481    0.000361\n",
              "37725    0.000355\n",
              "34391    0.000352\n",
              "17064    0.000348\n",
              "32519    0.000347\n",
              "45002    0.000345\n",
              "35533    0.000343\n",
              "21017    0.000343\n",
              "12147    0.000336\n",
              "2393     0.000333\n",
              "24712    0.000330\n",
              "43943    0.000329\n",
              "29473    0.000326\n",
              "26156    0.000325\n",
              "44417    0.000325\n",
              "28767    0.000321\n",
              "38591    0.000318\n",
              "14117    0.000313\n",
              "36907    0.000312\n",
              "1557     0.000312\n",
              "299      0.000308\n",
              "43098    0.000307\n",
              "36349    0.000300\n",
              "12784    0.000298\n",
              "42670    0.000298\n",
              "45285    0.000297\n",
              "1353     0.000293\n",
              "37681    0.000292\n",
              "30614    0.000292\n",
              "33584    0.000292\n",
              "1002     0.000287\n",
              "42615    0.000287\n",
              "40872    0.000287\n",
              "17985    0.000286\n",
              "41172    0.000285\n",
              "40340    0.000285\n",
              "35903    0.000280\n",
              "13506    0.000280\n",
              "29578    0.000279\n",
              "6375     0.000277\n",
              "43823    0.000276\n",
              "48044    0.000275\n",
              "649      0.000275\n",
              "11180    0.000273\n",
              "10491    0.000273\n",
              "17464    0.000271\n",
              "6169     0.000271\n",
              "29074    0.000270\n",
              "47078    0.000266\n",
              "40       0.000261\n",
              "3479     0.000261\n",
              "48023    0.000259\n",
              "14125    0.000257\n",
              "5511     0.000252\n",
              "5329     0.000251\n",
              "39348    0.000250\n",
              "36007    0.000243\n",
              "47820    0.000242\n",
              "22006    0.000242\n",
              "239      0.000240\n",
              "26082    0.000238\n",
              "32860    0.000238\n",
              "18519    0.000234\n",
              "13290    0.000234\n",
              "24795    0.000230\n",
              "30984    0.000229\n",
              "49108    0.000228\n",
              "37459    0.000227\n",
              "3318     0.000226\n",
              "28149    0.000224\n",
              "29055    0.000223\n",
              "26179    0.000222\n",
              "18860    0.000221\n",
              "875      0.000219\n",
              "20272    0.000217\n",
              "48125    0.000215\n",
              "47526    0.000212\n",
              "40607    0.000207\n",
              "32133    0.000202\n",
              "4956     0.000197\n",
              "41545    0.000196\n",
              "15467    0.000196\n",
              "21216    0.000194\n",
              "37375    0.000191\n",
              "48277    0.000187\n",
              "4279     0.000187\n",
              "43231    0.000186\n",
              "24806    0.000185\n",
              "45256    0.000185\n",
              "3553     0.000183\n",
              "25601    0.000182\n",
              "26640    0.000180\n",
              "37192    0.000179\n",
              "112      0.000178\n",
              "6455     0.000178\n",
              "8438     0.000172\n",
              "38721    0.000170\n",
              "18338    0.000170\n",
              "19934    0.000169\n",
              "36394    0.000166\n",
              "4040     0.000166\n",
              "39410    0.000165\n",
              "35159    0.000164\n",
              "42280    0.000162\n",
              "17203    0.000161\n",
              "16232    0.000158\n",
              "16484    0.000158\n",
              "43429    0.000152\n",
              "25151    0.000152\n",
              "42218    0.000149\n",
              "25359    0.000148\n",
              "40183    0.000146\n",
              "8302     0.000144\n",
              "37427    0.000133\n",
              "37986    0.000130\n",
              "1315     0.000123\n",
              "27683    0.000123\n",
              "5176     0.000121\n",
              "26666    0.000120\n",
              "49761    0.000118\n",
              "35833    0.000114\n",
              "5524     0.000108\n",
              "37536    0.000107\n",
              "37783    0.000099\n",
              "49150    0.000096\n",
              "34845    0.000096\n",
              "20854    0.000095\n",
              "12205    0.000092\n",
              "46081    0.000085\n",
              "16214    0.000084\n",
              "36942    0.000083\n",
              "45505    0.000081\n",
              "38716    0.000078\n",
              "198      0.000078\n",
              "27535    0.000078\n",
              "18899    0.000078\n",
              "43411    0.000077\n",
              "11184    0.000075\n",
              "10151    0.000069\n",
              "18501    0.000065\n",
              "36316    0.000063\n",
              "36429    0.000062\n",
              "7803     0.000062\n",
              "32102    0.000061\n",
              "35829    0.000059\n",
              "7060     0.000058\n",
              "33664    0.000057\n",
              "32391    0.000057\n",
              "38452    0.000054\n",
              "4940     0.000054\n",
              "31559    0.000050\n",
              "10106    0.000047\n",
              "16698    0.000043\n",
              "28879    0.000038\n",
              "45112    0.000038\n",
              "30233    0.000031\n",
              "10417    0.000029\n",
              "34818    0.000026\n",
              "34768    0.000025\n",
              "39002    0.000025\n",
              "45677    0.000024\n",
              "19287    0.000022\n",
              "17023    0.000021\n",
              "26663    0.000018\n",
              "37383    0.000017\n",
              "19088    0.000013\n",
              "42287    0.000012\n",
              "47972    0.000011\n",
              "20093    0.000011\n",
              "14614    0.000007\n",
              "37231    0.000007\n",
              "25746    0.000005\n",
              "33053    0.000003\n",
              "dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCpJJ4XZgfa4"
      },
      "source": [
        "## Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tiwcMCiqDSSp",
        "outputId": "c730f1f4-7795-41c7-ff92-d019fd138bea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family ['Calibri'] not found. Falling back to DejaVu Sans.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n",
            "WARNING:matplotlib.font_manager:findfont: Font family 'Calibri' not found.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Model Feature Importance\n",
        "xgb_feature_importance = pd.Series(xgb2.feature_importances_ / xgb2.feature_importances_.sum(),\n",
        "                                   index=['Moneyness(S/K)', 'Time to Maturity', 'Interest rate', 'Dividend','V0','theta','kappa','sigma','rho']).sort_values()\n",
        "plt.barh(xgb_feature_importance.index, xgb_feature_importance)\n",
        "plt.title(\"XGB: Feature Importance\\n$m \\in [0.2, 5.0]$\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wohB6RHsCo1J"
      },
      "source": [
        "# American Call Option - LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SWReBr191JP"
      },
      "outputs": [],
      "source": [
        "lgb_data = copy.deepcopy(data)\n",
        "\n",
        "# train/test data set for LGBM\n",
        "X_lgb = lgb_data.drop(['eurocall_fourier'], axis=1)\n",
        "y_lgb = lgb_data['eurocall_fourier']\n",
        "X_train_lgb, X_test_lgb, y_train_lgb, y_test_lgb = train_test_split(X_lgb, y_lgb, test_size=0.3, random_state=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-H4LeT7FZfo"
      },
      "source": [
        "## Model Fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "8D9jYv3891L1",
        "outputId": "5462e9f3-5736-48ab-c151-dbeaeaa041b9"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f0fbae42c669>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# {'lambda_l1': 0, 'lambda_l2': 1, 'max_bins': 31, 'min_data_in_leaf': 30, 'num_leaves': 31,'n_estimators':400}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mgrid_lgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBMRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_lgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_lgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_lgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mlgb_cv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_lgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Practicum/share_funcs.py\u001b[0m in \u001b[0;36mtrainmodel\u001b[0;34m(model, X_train, y_train, trained_params, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0mkflod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrained_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkflod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m   \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    872\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    819\u001b[0m                     )\n\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    822\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    823\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "param_lgb = {'num_leaves': [17, 31, 63],\n",
        "             'max_bins': [31 ,63, 127],\n",
        "             'min_data_in_leaf': [30, 60, 90],\n",
        "             'lambda_l1': [0, 0.1, 0.5],\n",
        "             'lambda_l2': [0, 1],\n",
        "             'num_estimators': [200, 400]\n",
        "             }\n",
        "# {'lambda_l1': 0, 'lambda_l2': 1, 'max_bins': 31, 'min_data_in_leaf': 30, 'num_leaves': 31,'n_estimators':400}\n",
        "\n",
        "grid_lgb = trainmodel(lgb.LGBMRegressor, X_train_lgb, y_train_lgb, param_lgb)\n",
        "lgb_cv_results = pd.DataFrame(grid_lgb.cv_results_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPsaixSoZ_ya"
      },
      "outputs": [],
      "source": [
        "file_path_lgb = '/content/drive/MyDrive/Practicum/lgb_cv_results_1w.csv'\n",
        "#lgb_cv_results.to_csv(file_path_lgb)\n",
        "lgb_cv_results = pd.read_csv(file_path_lgb, index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6O-D28Gh91OO",
        "outputId": "37d4c0e2-ae29-4c5e-9a19-04c737928dc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Best LGB Performance:\n",
            "LGBMRegressor(lambda_l1=0.1, lambda_l2=1, max_bins=31, min_data_in_leaf=30,\n",
            "              num_estimators=200)\n",
            "Train Set rmse:  0.01726\n",
            "LGB rmse:  0.01913 mae: 0.01206\n",
            "LGB r2:  0.99012\n"
          ]
        }
      ],
      "source": [
        "lgb1 = train_best_reg(lgb.LGBMRegressor, X_train_lgb, y_train_lgb, X_test_lgb, y_test_lgb,\n",
        "                      'LGB', **{'lambda_l1': 0.1, 'lambda_l2':1, 'max_bins': 31,'num_estimators':200, 'num_leaves': 31, 'min_data_in_leaf': 30})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAJ78EMehQ3k"
      },
      "source": [
        "## Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUwsbMRd91U-",
        "outputId": "d0f0056f-9513-470b-ebc0-49d10e9d341d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LGB Absolute Error (quantile): \n",
            "0.00    0.000\n",
            "0.25    0.002\n",
            "0.50    0.005\n",
            "0.75    0.011\n",
            "0.85    0.016\n",
            "0.90    0.019\n",
            "0.99    0.039\n",
            "1.00    0.647\n",
            "Name: eurocall_fourier, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Error\n",
        "y_test_predict_lgb = err_check(lgb1.predict(X_test_lgb))\n",
        "err_lgb = y_test_lgb - y_test_predict_lgb\n",
        "\n",
        "print('LGB Absolute Error (quantile): ')\n",
        "print(np.around(err_lgb.abs().quantile([0, 0.25, 0.5, 0.75, 0.85, 0.9, 0.99, 1]), decimals=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHQqIbqSht8p"
      },
      "source": [
        "## Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "YPFW_uo0hs_Z",
        "outputId": "1fd4e079-5e25-4971-ac9b-fab1b620b808"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Model Feature Importance\n",
        "lgb_feature_importance = pd.Series(lgb1.feature_importances_ / lgb1.feature_importances_.sum(),\n",
        "                                   index=['Moneyness(S/K)', 'Time to Maturity', 'Interest rate', 'Dividend','V0','theta','kappa','sigma','rho']).sort_values()\n",
        "plt.barh(lgb_feature_importance.index, lgb_feature_importance)\n",
        "plt.title(\"LGB: Feature Importance\\n$m \\in [0.2, 5.0]$\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szxXtMhoEWk9"
      },
      "source": [
        "# American Call Option - ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        },
        "id": "PO1hyDtw6MXn",
        "outputId": "64b40542-bd25-4fce-d76c-e27d27f4be4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-57-8c98b4abf13b>\", line 6, in <module>\n",
            "    X_ann['T_q'] = X_ann.g_T * X_ann.g_q\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/pandas/core/generic.py\", line 5487, in __getattr__\n",
            "    return object.__getattribute__(self, name)\n",
            "AttributeError: 'DataFrame' object has no attribute 'g_T'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'AttributeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.9/inspect.py\", line 1543, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.9/inspect.py\", line 1501, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.9/inspect.py\", line 709, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.9/inspect.py\", line 738, in getmodule\n",
            "    file = getabsfile(object, _filename)\n",
            "  File \"/usr/lib/python3.9/inspect.py\", line 722, in getabsfile\n",
            "    return os.path.normcase(os.path.abspath(_filename))\n",
            "  File \"/usr/lib/python3.9/posixpath.py\", line 380, in abspath\n",
            "    cwd = os.getcwd()\n",
            "OSError: [Errno 107] Transport endpoint is not connected\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ],
      "source": [
        "X_ann = data.drop(columns=['eurocall_fourier'], axis=1)\n",
        "#X_ann = X_ann.drop(columns=['g_eurocall'], axis=1)\n",
        "y_ann = data['eurocall_fourier']\n",
        "\n",
        "#X_ann['T_sigma'] = X_ann.g_T * X_ann.g_sigma\n",
        "X_ann['T_q'] = X_ann.g_T * X_ann.g_q\n",
        "X_ann['T_r'] = X_ann.g_T * X_ann.g_r\n",
        "\n",
        "X_train_ann, X_test_ann, y_train_ann, y_test_ann = train_test_split(X_ann, y_ann, test_size=0.3, random_state=10)\n",
        "#train_size = int(0.8 * len(X_train_ann))\n",
        "#X_train_ann, X_val_ann, y_train_ann, y_val_ann = train_test_split(X_train_ann, y_train_ann, test_size=0.3, random_state=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv5qycn9En15"
      },
      "source": [
        "## Model Fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k022uf0946ma"
      },
      "outputs": [],
      "source": [
        "class PricingNetwork2(nn.Module):\n",
        "  def __init__(self, mean=X_train_ann.mean(axis=0).values.astype(np.float32), std=X_train_ann.std(axis=0).values.astype(np.float32), neurons=64, x_features=X_train_ann.shape[1]):\n",
        "  #def __init__(self, neurons=64, x_features=5):\n",
        "    super(PricingNetwork2,self).__init__()\n",
        "    self.mean = mean\n",
        "    self.std = std\n",
        "    self.bottleneck = nn.Sequential(nn.Linear(x_features, neurons), nn.LeakyReLU(),\n",
        "                                     nn.Linear(neurons, neurons), nn.LeakyReLU(),\n",
        "                                     nn.Linear(neurons, neurons), nn.LeakyReLU(),\n",
        "                                     nn.Linear(neurons, neurons), nn.LeakyReLU(),\n",
        "                                     #nn.Linear(neurons, neurons), nn.LeakyReLU(),\n",
        "                                     nn.Linear(neurons, neurons), nn.LeakyReLU())\n",
        "    #self.bottleneck = nn.ModuleList([nn.Linear(x_features, neurons), nn.LeakyReLU()] + [nn.Linear(neurons, neurons), nn.LeakyReLU()] * 4)\n",
        "    self.final_layer = nn.Linear(neurons, 1)\n",
        "\n",
        "  def forward(self, X, **kwargs):\n",
        "    #X = (X - np.array([2.59564865,1.00528802,0.03986204,0.02523768,1.06051767], dtype=np.float32)) / np.array([1.38237971, 0.57541136, 0.02325452, 0.01445998, 0.55268058],dtype=np.float32)\n",
        "    #(X - X.mean(axis=0))/X.std(axis=0)\n",
        "    X = (X - self.mean) / self.std\n",
        "    X = self.bottleneck(X)\n",
        "    X  = self.final_layer(X)\n",
        "    return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Rhs0-ogEps5"
      },
      "source": [
        "## Error Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7V4l0uuNC7QH",
        "outputId": "8effc793-c198-41c5-ee37-c850d77924cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANN Absolute Error (quantile): \n",
            "0.00    0.000\n",
            "0.25    0.000\n",
            "0.50    0.000\n",
            "0.75    0.001\n",
            "0.85    0.002\n",
            "0.90    0.002\n",
            "0.99    0.005\n",
            "1.00    0.026\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "ann_model = torch.load('/content/drive/MyDrive/practicum_data-American_Option/with_eurocall.pt')\n",
        "\n",
        "print('ANN Absolute Error (quantile): ')\n",
        "with torch.no_grad():\n",
        "  err_ann = np.around((y_test_ann - pd.Series(ann_model(torch.tensor(X_test_ann.values.astype(np.float32))).flatten(), index=X_test_ann.index)), decimals=3)\n",
        "print((err_ann.abs().quantile([0,0.25,0.5,0.75,0.85,0.9,0.99,1])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0SizPhMBnma"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "a_laEUaxBp-l",
        "outputId": "ea001825-3423-4081-a1d5-0502c97906c5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c50140ef-12d7-4766-955e-3b27abcb6e9b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>g_m</th>\n",
              "      <th>g_T</th>\n",
              "      <th>g_r</th>\n",
              "      <th>g_q</th>\n",
              "      <th>abs_err_rf</th>\n",
              "      <th>abs_err_xgb</th>\n",
              "      <th>abs_err_lgb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27632</th>\n",
              "      <td>3.287892</td>\n",
              "      <td>1.759296</td>\n",
              "      <td>0.001603</td>\n",
              "      <td>0.033519</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>0.000008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36119</th>\n",
              "      <td>1.486242</td>\n",
              "      <td>1.967973</td>\n",
              "      <td>0.039346</td>\n",
              "      <td>0.042800</td>\n",
              "      <td>0.001425</td>\n",
              "      <td>0.000589</td>\n",
              "      <td>0.001674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4796</th>\n",
              "      <td>1.621878</td>\n",
              "      <td>0.671125</td>\n",
              "      <td>0.065681</td>\n",
              "      <td>0.021802</td>\n",
              "      <td>0.000032</td>\n",
              "      <td>0.000948</td>\n",
              "      <td>0.000562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3648</th>\n",
              "      <td>4.271923</td>\n",
              "      <td>1.674382</td>\n",
              "      <td>0.008339</td>\n",
              "      <td>0.005231</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000310</td>\n",
              "      <td>0.000082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24501</th>\n",
              "      <td>2.671971</td>\n",
              "      <td>1.813944</td>\n",
              "      <td>0.076365</td>\n",
              "      <td>0.014438</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.000070</td>\n",
              "      <td>0.000205</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c50140ef-12d7-4766-955e-3b27abcb6e9b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c50140ef-12d7-4766-955e-3b27abcb6e9b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c50140ef-12d7-4766-955e-3b27abcb6e9b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "            g_m       g_T       g_r       g_q  abs_err_rf  abs_err_xgb  \\\n",
              "27632  3.287892  1.759296  0.001603  0.033519    0.000004     0.000029   \n",
              "36119  1.486242  1.967973  0.039346  0.042800    0.001425     0.000589   \n",
              "4796   1.621878  0.671125  0.065681  0.021802    0.000032     0.000948   \n",
              "3648   4.271923  1.674382  0.008339  0.005231    0.000000     0.000310   \n",
              "24501  2.671971  1.813944  0.076365  0.014438    0.000017     0.000070   \n",
              "\n",
              "       abs_err_lgb  \n",
              "27632     0.000008  \n",
              "36119     0.001674  \n",
              "4796      0.000562  \n",
              "3648      0.000082  \n",
              "24501     0.000205  "
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "err_table = pd.concat([X_test_rf, err_rf.abs(), err_xgb.abs(), err_lgb.abs()], axis=1)\n",
        "err_table.columns = ['g_m', 'g_T', 'g_r', 'g_q',   'abs_err_rf', 'abs_err_xgb', 'abs_err_lgb']\n",
        "err_table.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44-OSPiLCmWe"
      },
      "source": [
        "## Moneyness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4szTVQiHB29Z",
        "outputId": "e355582c-6641-49eb-b140-3cf16c891312"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#OTM =  12498 ; %OTM =  0.8332\n",
            "#ATM =  0 ; %ATM =  0.0\n",
            "#ITM =  2502 ; %OTM =  0.1668\n"
          ]
        }
      ],
      "source": [
        "print('#OTM = ', err_table[err_table['g_m'] > 1].shape[0], '; %OTM = ', err_table[err_table['g_m'] > 1].shape[0]/err_table.shape[0])\n",
        "print('#ATM = ', err_table[err_table['g_m'] == 1].shape[0], '; %ATM = ', err_table[err_table['g_m'] == 1].shape[0]/err_table.shape[0])\n",
        "print('#ITM = ', err_table[err_table['g_m'] < 1].shape[0], '; %OTM = ', err_table[err_table['g_m'] < 1].shape[0]/err_table.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "WO5r_LzmCtEk",
        "outputId": "cff31a6c-6f82-4ad9-d767-35070e02a314"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9f7d7750-84d8-4210-818c-23b1866a75d0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>g_m</th>\n",
              "      <th>g_T</th>\n",
              "      <th>g_r</th>\n",
              "      <th>g_q</th>\n",
              "      <th>g_sigma</th>\n",
              "      <th>g_eurocall</th>\n",
              "      <th>abs_err_rf</th>\n",
              "      <th>abs_err_xgb</th>\n",
              "      <th>abs_err_lgb</th>\n",
              "      <th>abs_err_ann</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.00</th>\n",
              "      <td>1.000</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.051</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.25</th>\n",
              "      <td>2.035</td>\n",
              "      <td>0.088</td>\n",
              "      <td>0.021</td>\n",
              "      <td>0.013</td>\n",
              "      <td>0.514</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.50</th>\n",
              "      <td>3.024</td>\n",
              "      <td>0.277</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.026</td>\n",
              "      <td>0.983</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.75</th>\n",
              "      <td>4.000</td>\n",
              "      <td>1.047</td>\n",
              "      <td>0.060</td>\n",
              "      <td>0.038</td>\n",
              "      <td>1.456</td>\n",
              "      <td>0.118</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.85</th>\n",
              "      <td>4.402</td>\n",
              "      <td>1.449</td>\n",
              "      <td>0.068</td>\n",
              "      <td>0.042</td>\n",
              "      <td>1.689</td>\n",
              "      <td>0.243</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.90</th>\n",
              "      <td>4.588</td>\n",
              "      <td>1.699</td>\n",
              "      <td>0.071</td>\n",
              "      <td>0.045</td>\n",
              "      <td>1.785</td>\n",
              "      <td>0.345</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.95</th>\n",
              "      <td>4.809</td>\n",
              "      <td>2.044</td>\n",
              "      <td>0.076</td>\n",
              "      <td>0.047</td>\n",
              "      <td>1.906</td>\n",
              "      <td>0.488</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.99</th>\n",
              "      <td>4.964</td>\n",
              "      <td>2.044</td>\n",
              "      <td>0.079</td>\n",
              "      <td>0.050</td>\n",
              "      <td>1.979</td>\n",
              "      <td>0.655</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.00</th>\n",
              "      <td>4.999</td>\n",
              "      <td>2.044</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.050</td>\n",
              "      <td>2.000</td>\n",
              "      <td>0.805</td>\n",
              "      <td>0.013</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.008</td>\n",
              "      <td>0.009</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f7d7750-84d8-4210-818c-23b1866a75d0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9f7d7750-84d8-4210-818c-23b1866a75d0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9f7d7750-84d8-4210-818c-23b1866a75d0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        g_m    g_T    g_r    g_q  g_sigma  g_eurocall  abs_err_rf  \\\n",
              "0.00  1.000  0.011  0.000  0.000    0.051       0.000       0.000   \n",
              "0.25  2.035  0.088  0.021  0.013    0.514       0.000       0.000   \n",
              "0.50  3.024  0.277  0.040  0.026    0.983       0.005       0.000   \n",
              "0.75  4.000  1.047  0.060  0.038    1.456       0.118       0.000   \n",
              "0.85  4.402  1.449  0.068  0.042    1.689       0.243       0.001   \n",
              "0.90  4.588  1.699  0.071  0.045    1.785       0.345       0.001   \n",
              "0.95  4.809  2.044  0.076  0.047    1.906       0.488       0.001   \n",
              "0.99  4.964  2.044  0.079  0.050    1.979       0.655       0.003   \n",
              "1.00  4.999  2.044  0.080  0.050    2.000       0.805       0.013   \n",
              "\n",
              "      abs_err_xgb  abs_err_lgb  abs_err_ann  \n",
              "0.00        0.000        0.000        0.000  \n",
              "0.25        0.000        0.000        0.000  \n",
              "0.50        0.000        0.000        0.000  \n",
              "0.75        0.000        0.001        0.001  \n",
              "0.85        0.001        0.001        0.002  \n",
              "0.90        0.001        0.001        0.002  \n",
              "0.95        0.001        0.002        0.003  \n",
              "0.99        0.002        0.003        0.004  \n",
              "1.00        0.005        0.008        0.009  "
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# OTM\n",
        "np.around(err_table[err_table['g_m'] > 1].quantile([0,0.25,0.5,0.75,0.85,0.90,0.95,0.99,1]), decimals=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "Qu1RGnZmC27r",
        "outputId": "b8c35ee9-9717-4309-ea5e-932944a4c658"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c2ff6016-c1c6-405f-8170-abfda098d428\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>g_m</th>\n",
              "      <th>g_T</th>\n",
              "      <th>g_r</th>\n",
              "      <th>g_q</th>\n",
              "      <th>g_sigma</th>\n",
              "      <th>g_eurocall</th>\n",
              "      <th>abs_err_rf</th>\n",
              "      <th>abs_err_xgb</th>\n",
              "      <th>abs_err_lgb</th>\n",
              "      <th>abs_err_ann</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.00</th>\n",
              "      <td>0.201</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.051</td>\n",
              "      <td>0.022</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.25</th>\n",
              "      <td>0.364</td>\n",
              "      <td>0.088</td>\n",
              "      <td>0.020</td>\n",
              "      <td>0.014</td>\n",
              "      <td>0.504</td>\n",
              "      <td>0.338</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.50</th>\n",
              "      <td>0.577</td>\n",
              "      <td>0.277</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.026</td>\n",
              "      <td>0.984</td>\n",
              "      <td>0.519</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.75</th>\n",
              "      <td>0.792</td>\n",
              "      <td>1.047</td>\n",
              "      <td>0.061</td>\n",
              "      <td>0.038</td>\n",
              "      <td>1.434</td>\n",
              "      <td>0.685</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.001</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.85</th>\n",
              "      <td>0.874</td>\n",
              "      <td>1.449</td>\n",
              "      <td>0.069</td>\n",
              "      <td>0.042</td>\n",
              "      <td>1.686</td>\n",
              "      <td>0.738</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.90</th>\n",
              "      <td>0.917</td>\n",
              "      <td>1.699</td>\n",
              "      <td>0.072</td>\n",
              "      <td>0.045</td>\n",
              "      <td>1.782</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.002</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.95</th>\n",
              "      <td>0.960</td>\n",
              "      <td>2.044</td>\n",
              "      <td>0.077</td>\n",
              "      <td>0.047</td>\n",
              "      <td>1.898</td>\n",
              "      <td>0.784</td>\n",
              "      <td>0.004</td>\n",
              "      <td>0.003</td>\n",
              "      <td>0.005</td>\n",
              "      <td>0.005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0.99</th>\n",
              "      <td>0.993</td>\n",
              "      <td>2.044</td>\n",
              "      <td>0.079</td>\n",
              "      <td>0.050</td>\n",
              "      <td>1.967</td>\n",
              "      <td>0.827</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.007</td>\n",
              "      <td>0.011</td>\n",
              "      <td>0.007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.00</th>\n",
              "      <td>1.000</td>\n",
              "      <td>2.044</td>\n",
              "      <td>0.080</td>\n",
              "      <td>0.050</td>\n",
              "      <td>2.000</td>\n",
              "      <td>0.912</td>\n",
              "      <td>0.036</td>\n",
              "      <td>0.026</td>\n",
              "      <td>0.045</td>\n",
              "      <td>0.026</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2ff6016-c1c6-405f-8170-abfda098d428')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c2ff6016-c1c6-405f-8170-abfda098d428 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c2ff6016-c1c6-405f-8170-abfda098d428');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        g_m    g_T    g_r    g_q  g_sigma  g_eurocall  abs_err_rf  \\\n",
              "0.00  0.201  0.011  0.000  0.000    0.051       0.022       0.000   \n",
              "0.25  0.364  0.088  0.020  0.014    0.504       0.338       0.000   \n",
              "0.50  0.577  0.277  0.040  0.026    0.984       0.519       0.001   \n",
              "0.75  0.792  1.047  0.061  0.038    1.434       0.685       0.002   \n",
              "0.85  0.874  1.449  0.069  0.042    1.686       0.738       0.002   \n",
              "0.90  0.917  1.699  0.072  0.045    1.782       0.760       0.003   \n",
              "0.95  0.960  2.044  0.077  0.047    1.898       0.784       0.004   \n",
              "0.99  0.993  2.044  0.079  0.050    1.967       0.827       0.010   \n",
              "1.00  1.000  2.044  0.080  0.050    2.000       0.912       0.036   \n",
              "\n",
              "      abs_err_xgb  abs_err_lgb  abs_err_ann  \n",
              "0.00        0.000        0.000        0.000  \n",
              "0.25        0.000        0.001        0.001  \n",
              "0.50        0.001        0.001        0.002  \n",
              "0.75        0.001        0.003        0.002  \n",
              "0.85        0.002        0.003        0.003  \n",
              "0.90        0.002        0.004        0.004  \n",
              "0.95        0.003        0.005        0.005  \n",
              "0.99        0.007        0.011        0.007  \n",
              "1.00        0.026        0.045        0.026  "
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# ITM\n",
        "np.around(err_table[err_table['g_m'] < 1].quantile([0,0.25,0.5,0.75,0.85,0.90,0.95,0.99,1]), decimals=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-auLYONiUhCG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}